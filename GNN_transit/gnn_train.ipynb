{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 1. PARSE TSP FILE (PER-INSTANCE x_mid, y_mid)\n",
    "##################################################\n",
    "\n",
    "def parse_tsp_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a .txt file where each line represents an N-city TSP instance.\n",
    "    Format (single line):\n",
    "      x1 y1 x2 y2 ... xN yN output r1 r2 ... rN r1\n",
    "\n",
    "    Returns list of dict, each containing:\n",
    "      - 'points': list of (x,y)\n",
    "      - 'solution_edges': set((u,v)) 0-based edges\n",
    "      - 'x_mid', 'y_mid': medians for that instance\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    print(f\"Parsing file: {file_path}\")\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in tqdm(lines, desc=\"Parsing lines\"):\n",
    "        parts = line.strip().split()\n",
    "        if \"output\" not in parts:\n",
    "            continue\n",
    "\n",
    "        output_index = parts.index(\"output\")\n",
    "        coord_values = parts[:output_index]\n",
    "        route_values = parts[output_index + 1:]\n",
    "\n",
    "        if len(coord_values) % 2 != 0:\n",
    "            raise ValueError(\"Number of coordinate values must be even (x, y pairs).\")\n",
    "\n",
    "        N = len(coord_values) // 2\n",
    "        points = [(float(coord_values[2*i]), float(coord_values[2*i+1])) for i in range(N)]\n",
    "\n",
    "        x_mid = np.median([p[0] for p in points])\n",
    "        y_mid = np.median([p[1] for p in points])\n",
    "\n",
    "        route = list(map(int, route_values))\n",
    "        if len(route) != N + 1 or route[0] != route[-1]:\n",
    "            raise ValueError(\"Route must have N+1 entries and start/end with the same city.\")\n",
    "\n",
    "        sol_edges = set()\n",
    "        for i in range(len(route) - 1):\n",
    "            u = route[i] - 1\n",
    "            v = route[i+1] - 1\n",
    "            if not (0 <= u < N and 0 <= v < N):\n",
    "                raise ValueError(f\"Invalid route index {u},{v}. Must be between 1 and N.\")\n",
    "            if u != v:\n",
    "                sol_edges.add((u, v))\n",
    "\n",
    "        instances.append({\n",
    "            'points': points,\n",
    "            'solution_edges': sol_edges,\n",
    "            'x_mid': x_mid,\n",
    "            'y_mid': y_mid\n",
    "        })\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 2. HELPER FUNCTIONS\n",
    "##################################################\n",
    "\n",
    "def quadrant(x, y, x_mid, y_mid):\n",
    "    # Q0: x >= x_mid, y >= y_mid\n",
    "    # Q1: x <  x_mid, y >= y_mid\n",
    "    # Q2: x <  x_mid, y <  y_mid\n",
    "    # Q3: x >= x_mid, y <  y_mid\n",
    "    if x >= x_mid and y >= y_mid:\n",
    "        return 0\n",
    "    elif x < x_mid and y >= y_mid:\n",
    "        return 1\n",
    "    elif x < x_mid and y < y_mid:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def build_kd_tree(points):\n",
    "    return cKDTree(points)\n",
    "\n",
    "def get_k_neighbors(tree, query_point, k):\n",
    "    dist, idx = tree.query(query_point, k=k)\n",
    "    if k == 1:\n",
    "        idx = np.array([idx])\n",
    "        dist = np.array([dist])\n",
    "    return dist, idx\n",
    "\n",
    "def compute_instance_thresholds(points, x_mid, y_mid, percentile=20):\n",
    "    \"\"\"\n",
    "    For axis closeness:\n",
    "      d_x, d_y = percentile-based thresholds for |x - x_mid| and |y - y_mid|.\n",
    "    \"\"\"\n",
    "    dx_vals = [abs(x - x_mid) for (x,y) in points]\n",
    "    dy_vals = [abs(y - y_mid) for (x,y) in points]\n",
    "    d_x = np.percentile(dx_vals, percentile)\n",
    "    d_y = np.percentile(dy_vals, percentile)\n",
    "    return d_x, d_y\n",
    "\n",
    "def is_axis_close(x, y, x_mid, y_mid, d_x, d_y):\n",
    "    return (abs(x - x_mid) <= d_x) or (abs(y - y_mid) <= d_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 3. DISTANCE-BASED EDGE PRUNING: PERCENTILE THRESHOLD\n",
    "##################################################\n",
    "\n",
    "def compute_instance_dist_threshold(points, x_mid, y_mid, d_x, d_y, percentile=90):\n",
    "    \"\"\"\n",
    "    1) Identify axis-close points (just as in build_graph_instance).\n",
    "    \n",
    "    2) Collect all pairwise distances among these axis-close points\n",
    "       (if that set is large, be mindful of O(N^2) complexity).\n",
    "    3) Return the distance at the specified percentile. \n",
    "       e.g., 90 => skip edges above the 90th percentile distance.\n",
    "    \"\"\"\n",
    "    # Step A: basic axis closeness\n",
    "    axis_close_mask = [\n",
    "        is_axis_close(x, y, x_mid, y_mid, d_x, d_y)\n",
    "        for (x,y) in points\n",
    "    ]\n",
    "    axis_close_indices = [i for i,flag in enumerate(axis_close_mask) if flag]\n",
    "\n",
    "    # If no axis-close points, return a large threshold to avoid\n",
    "    # pruning everything\n",
    "    if len(axis_close_indices) < 2:\n",
    "        return float('inf')  # no distance-based pruning possible\n",
    "\n",
    "    coords = np.array(points)\n",
    "    axis_close_coords = coords[axis_close_indices]  # shape (M,2)\n",
    "\n",
    "    # Step B: gather pairwise distances (O(M^2))\n",
    "    dist_list = []\n",
    "    M = axis_close_coords.shape[0]\n",
    "    for i in range(M):\n",
    "        for j in range(i+1, M):\n",
    "            dx = axis_close_coords[j,0] - axis_close_coords[i,0]\n",
    "            dy = axis_close_coords[j,1] - axis_close_coords[i,1]\n",
    "            dist_ij = np.sqrt(dx*dx + dy*dy)\n",
    "            dist_list.append(dist_ij)\n",
    "\n",
    "    if len(dist_list) == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    # Step C: percentile\n",
    "    dist_threshold = np.percentile(dist_list, percentile)\n",
    "    return dist_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 4. BUILD GRAPH (k-NN + Dist Threshold)\n",
    "##################################################\n",
    "\n",
    "def build_graph_instance(points, \n",
    "                         x_mid, y_mid, \n",
    "                         d_x, d_y, \n",
    "                         k=3,\n",
    "                         solution_edges=None,\n",
    "                         add_solution_edges = False,\n",
    "                         dist_threshold=float('inf')):\n",
    "    \"\"\"\n",
    "    This function prunes edges in two ways:\n",
    "      1) Only consider axis-close points as sources (plus endpoints of cross-quadrant solution edges).\n",
    "      2) Among the k-NN in each quadrant, skip any edge with dist > dist_threshold.\n",
    "    \"\"\"\n",
    "    coords = np.array(points)\n",
    "    N = len(points)\n",
    "\n",
    "    quads = [quadrant(x, y, x_mid, y_mid) for (x,y) in points]\n",
    "\n",
    "    # Identify axis-close points\n",
    "    axis_close_mask = [\n",
    "        is_axis_close(x, y, x_mid, y_mid, d_x, d_y)\n",
    "        for (x,y) in points\n",
    "    ]\n",
    "\n",
    "    # Enforce solution cross-quadrant edges\n",
    "    if solution_edges is not None and add_solution_edges is True:\n",
    "        for (u, v) in solution_edges:\n",
    "            if quads[u] != quads[v]:\n",
    "                axis_close_mask[u] = True\n",
    "                axis_close_mask[v] = True\n",
    "\n",
    "    axis_close_indices = np.where(axis_close_mask)[0]\n",
    "\n",
    "    # kd-trees per quadrant\n",
    "    quad_points = [[] for _ in range(4)]\n",
    "    quad_indices = [[] for _ in range(4)]\n",
    "    for i, (x,y) in enumerate(points):\n",
    "        Q = quads[i]\n",
    "        quad_points[Q].append((x,y))\n",
    "        quad_indices[Q].append(i)\n",
    "\n",
    "    quad_points = [np.array(qp) if len(qp)>0 else np.zeros((0,2)) for qp in quad_points]\n",
    "    quad_trees = [\n",
    "        build_kd_tree(qp) if len(qp)>0 else None\n",
    "        for qp in quad_points\n",
    "    ]\n",
    "\n",
    "    edge_src, edge_dst, edge_labels = [], [], []\n",
    "\n",
    "    # Build edges from axis-close points -> kNN in other quadrants\n",
    "    for global_idx in axis_close_indices:\n",
    "        px, py = points[global_idx]\n",
    "        Qsrc = quads[global_idx]\n",
    "        for Qtgt in range(4):\n",
    "            if Qtgt == Qsrc:\n",
    "                continue\n",
    "            if quad_trees[Qtgt] is None or len(quad_points[Qtgt]) == 0:\n",
    "                continue\n",
    "\n",
    "            # effective k if quadrant has fewer than k points\n",
    "            k_eff = min(k, len(quad_points[Qtgt]))\n",
    "            if k_eff == 0:\n",
    "                continue\n",
    "\n",
    "            dist_arr, idx_arr = get_k_neighbors(quad_trees[Qtgt], [px, py], k_eff)\n",
    "            for neigh_i in range(k_eff):\n",
    "                nbr_global = quad_indices[Qtgt][idx_arr[neigh_i]]\n",
    "                d_ij = dist_arr[neigh_i]\n",
    "\n",
    "                # Skip if distance > dist_threshold\n",
    "                if d_ij > dist_threshold:\n",
    "                    continue\n",
    "\n",
    "                edge_src.append(global_idx)\n",
    "                edge_dst.append(nbr_global)\n",
    "\n",
    "                if solution_edges is not None:\n",
    "                    if (global_idx, nbr_global) in solution_edges or (nbr_global, global_idx) in solution_edges:\n",
    "                        label = 1.0\n",
    "                    else:\n",
    "                        label = 0.0\n",
    "                else:\n",
    "                    label = 0.0\n",
    "                edge_labels.append(label)\n",
    "\n",
    "                # reverse edge\n",
    "                edge_src.append(nbr_global)\n",
    "                edge_dst.append(global_idx)\n",
    "                edge_labels.append(label)\n",
    "\n",
    "    x_t = torch.tensor(coords, dtype=torch.float)\n",
    "    edge_index = torch.tensor([edge_src, edge_dst], dtype=torch.long)\n",
    "    y_t = torch.tensor(edge_labels, dtype=torch.float).view(-1,1)\n",
    "\n",
    "    return Data(x=x_t, edge_index=edge_index, y=y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 5. GNN MODEL WITH SIGMOID OUTPUT\n",
    "##################################################\n",
    "\n",
    "class EdgeClassifierGNN(nn.Module):\n",
    "    def __init__(self, in_channels=2, hidden_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GraphConv(in_channels, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GraphConv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # We apply Sigmoid directly -> use BCELoss\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        row, col = edge_index\n",
    "        edge_emb = torch.cat([x[row], x[col]], dim=-1)  # (M,2*hidden_dim)\n",
    "        out = self.mlp(edge_emb)  # (M,1) in [0,1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 6. TRAIN & EVALUATE (Using BCELoss)\n",
    "##################################################\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device, epoch_num):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loader_iter = tqdm(loader, desc=f\"Epoch {epoch_num} (Train)\")\n",
    "    for data in loader_iter:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)  # sigmoid probabilities\n",
    "        loss = criterion(out, data.y)         # BCELoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device, mode=\"Val\"):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loader_iter = tqdm(loader, desc=f\"Evaluating ({mode})\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for data in loader_iter:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (out > 0.5).float()\n",
    "            correct += (preds == data.y).sum().item()\n",
    "            total   += data.y.numel()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: tsp-data/tsp50_train_concorde.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing lines: 100%|██████████| 990000/990000 [00:44<00:00, 22319.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: tsp-data/tsp50_val_concorde.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing lines: 100%|██████████| 10000/10000 [00:00<00:00, 22632.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: tsp-data/tsp50_test_concorde.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing lines: 100%|██████████| 10000/10000 [00:00<00:00, 24439.84it/s]\n",
      "Building Graphs: 100%|██████████| 990000/990000 [16:04<00:00, 1026.01it/s] \n",
      "Building Graphs: 100%|██████████| 10000/10000 [00:08<00:00, 1224.53it/s]\n",
      "Building Graphs: 100%|██████████| 10000/10000 [00:08<00:00, 1214.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 (Train):   1%|▏         | 393/30938 [01:10<1:31:21,  5.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 72\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[146], line 10\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion, device, epoch_num)\u001b[0m\n\u001b[1;32m      8\u001b[0m loader_iter \u001b[38;5;241m=\u001b[39m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Train)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader_iter:\n\u001b[0;32m---> 10\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)  \u001b[38;5;66;03m# sigmoid probabilities\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/data.py:362\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/data.py:342\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 342\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/storage.py:897\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/data.py:363\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 363\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# 7. MAIN EXAMPLE\n",
    "##################################################\n",
    "\n",
    "\n",
    "# Suppose we have TSP files of size 50\n",
    "problem_size = 50\n",
    "train_file = f\"tsp-data/tsp{problem_size}_train_concorde.txt\"\n",
    "val_file   = f\"tsp-data/tsp{problem_size}_val_concorde.txt\"\n",
    "test_file  = f\"tsp-data/tsp{problem_size}_test_concorde.txt\"\n",
    "\n",
    "train_instances = parse_tsp_file(train_file)\n",
    "val_instances   = parse_tsp_file(val_file)\n",
    "test_instances  = parse_tsp_file(test_file)\n",
    "\n",
    "\n",
    "# For axis closeness\n",
    "percentile_axis_close = 20  \n",
    "# For distance threshold (e.g., skip edges above 90th percentile)\n",
    "percentile_dist = 50  \n",
    "k_nn = 3              \n",
    "\n",
    "def build_dataset(instances, is_train = False):\n",
    "    data_list = []\n",
    "    for inst in tqdm(instances, desc=\"Building Graphs\"):\n",
    "        points = inst['points']\n",
    "        sol_edges = inst['solution_edges']\n",
    "        x_mid_i   = inst['x_mid']\n",
    "        y_mid_i   = inst['y_mid']\n",
    "\n",
    "        # Step 1: compute d_x, d_y\n",
    "        d_x_i, d_y_i = compute_instance_thresholds(points, x_mid_i, y_mid_i, percentile_axis_close)\n",
    "\n",
    "        # Step 2: compute the distance threshold for this instance\n",
    "        dist_thr_i = compute_instance_dist_threshold(\n",
    "            points, x_mid_i, y_mid_i, d_x_i, d_y_i,\n",
    "            percentile=percentile_dist\n",
    "        )\n",
    "\n",
    "        # Step 3: build graph\n",
    "        data = build_graph_instance(\n",
    "            points,\n",
    "            x_mid_i, y_mid_i,\n",
    "            d_x_i, d_y_i,\n",
    "            k=k_nn,\n",
    "            solution_edges=sol_edges,\n",
    "            add_solution_edges=is_train,\n",
    "            dist_threshold=dist_thr_i\n",
    "        )\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_data_list = build_dataset(train_instances, is_train=True)\n",
    "val_data_list   = build_dataset(val_instances, is_train=False)\n",
    "test_data_list  = build_dataset(test_instances, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data_list,   batch_size=1, shuffle=False)\n",
    "test_loader  = DataLoader(test_data_list,  batch_size=1, shuffle=False)\n",
    "\n",
    "# Use MPS or fallback to CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = EdgeClassifierGNN(in_channels=2, hidden_dim=64, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Because final layer is Sigmoid\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, epoch)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device, \"Val\")\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {train_loss:.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Final test\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device, \"Test\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsp_instance(instance, data, axis_close_mask, skip_duplicates=True):\n",
    "    \"\"\"\n",
    "    Visualize one TSP instance with pruned edges.\n",
    "    \n",
    "    Args:\n",
    "        instance: A dict with:\n",
    "          - 'points': list[(x,y)]\n",
    "          - 'solution_edges': set((u,v))  (0-based) [Optional, if you want to see actual route edges]\n",
    "          - 'x_mid', 'y_mid': floats dividing the plane\n",
    "        data: PyG Data object from build_graph_instance (with x, edge_index, y)\n",
    "        axis_close_mask: Boolean list (or array) of length N\n",
    "                        indicating which points are axis-close.\n",
    "        skip_duplicates: If True, skip every second edge to avoid plotting\n",
    "                         the bidirectional duplicate.\n",
    "\n",
    "    Returns:\n",
    "        A matplotlib figure and axis.\n",
    "    \"\"\"\n",
    "    points = instance['points']\n",
    "    x_mid = instance['x_mid']\n",
    "    y_mid = instance['y_mid']\n",
    "    N = len(points)\n",
    "\n",
    "    # Convert PyG data to numpy for easy indexing\n",
    "    node_coords = data.x.cpu().numpy()  # shape (N,2)\n",
    "    edge_idx = data.edge_index.cpu().numpy()  # shape (2, M)\n",
    "    edge_labels = data.y.cpu().numpy()  # shape (M,1)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.set_title(\"TSP Instance Visualization\")\n",
    "\n",
    "    # 1. Plot vertical/horizontal dividing lines\n",
    "    ax.axvline(x_mid, color='gray', linestyle='--', alpha=0.7, label='x_mid')\n",
    "    ax.axhline(y_mid, color='gray', linestyle='--', alpha=0.7, label='y_mid')\n",
    "\n",
    "    # 2. Plot all points\n",
    "    all_x = [p[0] for p in points]\n",
    "    all_y = [p[1] for p in points]\n",
    "    ax.scatter(all_x, all_y, c='lightgray', marker='o', label='All Points')\n",
    "\n",
    "    # 3. Plot axis-close (kept) points\n",
    "    axis_kept_x = [p[0] for i,p in enumerate(points) if axis_close_mask[i]]\n",
    "    axis_kept_y = [p[1] for i,p in enumerate(points) if axis_close_mask[i]]\n",
    "    ax.scatter(axis_kept_x, axis_kept_y, c='blue', marker='o', label='Axis-Close Points')\n",
    "\n",
    "    # 4. Plot candidate edges\n",
    "    # We skip duplicates by stepping in increments of 2 if skip_duplicates=True\n",
    "    # (because each edge was added in both directions).\n",
    "    step = 2 if skip_duplicates else 1\n",
    "    for i in range(0, edge_idx.shape[1], step):\n",
    "        u = edge_idx[0, i]\n",
    "        v = edge_idx[1, i]\n",
    "        x1, y1 = node_coords[u]\n",
    "        x2, y2 = node_coords[v]\n",
    "\n",
    "        edge_label = edge_labels[i, 0]  # 0 or 1\n",
    "        if edge_label == 1:\n",
    "            # A \"crossover\" edge\n",
    "            ax.plot([x1, x2], [y1, y2], c='red', linewidth=2.0, alpha=0.9)\n",
    "        else:\n",
    "            # Just a candidate edge\n",
    "            ax.plot([x1, x2], [y1, y2], c='gray', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # 5. (Optional) Plot actual solution edges if you want to compare:\n",
    "    #    instance['solution_edges'] might exist. These are 0-based edges for the route.\n",
    "    #    If you want to highlight them, you can do something like:\n",
    "    #\n",
    "    '''\n",
    "    for (u,v) in instance['solution_edges']:\n",
    "         x1, y1 = points[u]\n",
    "         x2, y2 = points[v]\n",
    "         ax.plot([x1, x2], [y1, y2], c='green', linewidth=2, alpha=0.8)\n",
    "    '''\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_close_mask(instance, d_x, d_y):\n",
    "    \"\"\"\n",
    "    Replicates the logic from build_graph_instance to determine\n",
    "    which points are marked axis-close.\n",
    "\n",
    "    1) Mark points whose |x - x_mid| <= d_x or |y - y_mid| <= d_y.\n",
    "    2) For each solution edge that crosses quadrants, mark endpoints.\n",
    "    \"\"\"\n",
    "    points = instance['points']\n",
    "    x_mid, y_mid = instance['x_mid'], instance['y_mid']\n",
    "    sol_edges = instance['solution_edges']\n",
    "    N = len(points)\n",
    "\n",
    "    # (A) Basic closeness to axes\n",
    "    mask = []\n",
    "    for (x, y) in points:\n",
    "        is_close = (abs(x - x_mid) <= d_x) or (abs(y - y_mid) <= d_y)\n",
    "        mask.append(is_close)\n",
    "\n",
    "    # (B) Quadrant-based cross-quadrant solution edges\n",
    "    quads = []\n",
    "    for (x, y) in points:\n",
    "        if x >= x_mid and y >= y_mid:\n",
    "            quads.append(0)\n",
    "        elif x < x_mid and y >= y_mid:\n",
    "            quads.append(1)\n",
    "        elif x < x_mid and y < y_mid:\n",
    "            quads.append(2)\n",
    "        else:\n",
    "            quads.append(3)\n",
    "\n",
    "    for (u, v) in sol_edges:\n",
    "        if quads[u] != quads[v]:\n",
    "            mask[u] = True\n",
    "            mask[v] = True\n",
    "\n",
    "    return mask\n",
    "\n",
    "vis = False\n",
    "if vis == True:\n",
    "    i = 100\n",
    "    sample_instance = train_instances[i]\n",
    "    points = sample_instance['points']\n",
    "    x_mid_i = sample_instance['x_mid']\n",
    "    y_mid_i = sample_instance['y_mid']\n",
    "    percentile_dist = 50\n",
    "\n",
    "    # compute instance-based threshold for closeness\n",
    "    d_x_i, d_y_i = compute_instance_thresholds(points, x_mid_i, y_mid_i, percentile=20)\n",
    "\n",
    "    dist_thr_i = compute_instance_dist_threshold(\n",
    "            points, x_mid_i, y_mid_i, d_x_i, d_y_i,\n",
    "            percentile=percentile_dist\n",
    "        )\n",
    "    \n",
    "\n",
    "    # build graph\n",
    "    sample_data = build_graph_instance(\n",
    "        points,\n",
    "        x_mid_i, y_mid_i,\n",
    "        d_x_i, d_y_i,\n",
    "        k=3,\n",
    "        solution_edges=sample_instance['solution_edges'],\n",
    "        dist_threshold=dist_thr_i\n",
    "    )\n",
    "\n",
    "    # replicate axis_close_mask for plotting\n",
    "    axis_mask = get_axis_close_mask(sample_instance, d_x_i, d_y_i)\n",
    "\n",
    "    fig, ax = plot_tsp_instance(sample_instance, sample_data, axis_mask)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
