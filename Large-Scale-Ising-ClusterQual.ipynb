{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestCentroid, kneighbors_graph\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import KDTree, cKDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from concorde.tsp import TSPSolver\n",
    "from math import sqrt, ceil, inf, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "tsp_dir = os.path.join(root_dir, \"../tsplib\")\n",
    "concorde_dir = os.path.join(root_dir, \"../pyconcorde/concorde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, root_dir)\n",
    "sys.path.insert(0, tsp_dir)\n",
    "#sys.path.insert(0, concorde_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tsp_data():\n",
    "    ## Load a tsp library and Create a dictionary \"tsp_database\" of Name-X/Y coordinates.\n",
    "\n",
    "    tsp_database = {}\n",
    "    cities = os.listdir(tsp_dir)\n",
    "    \n",
    "    for city in cities:\n",
    "        if city.endswith(\".tsp\"):\n",
    "            with open(tsp_dir + '/' + city, 'r') as infile:\n",
    "                lines = infile.readlines()\n",
    "                for i in range(0, len(lines)):\n",
    "                    line = lines[i]\n",
    "                    if \"DIMENSION\" in line:\n",
    "                        Dimension = line.strip().split(':')[1]\n",
    "                        if not Dimension.isdigit():\n",
    "                            continue\n",
    "                    if \"EDGE_WEIGHT_TYPE\" in line:\n",
    "                        EdgeWeightType = line.strip().split()[1]\n",
    "                        if EdgeWeightType != \"EUC_2D\":\n",
    "                            continue\n",
    "                    if \"NODE_COORD_SECTION\" in line:\n",
    "                        x_y = None\n",
    "                        nodelist_x = []\n",
    "                        nodelist_y = []\n",
    "        \n",
    "                        for j in range (1, int(Dimension)):\n",
    "                            x_y = lines[i+1].strip().split()[1:]\n",
    "    #                        print(x_y)\n",
    "    #                        import pdb; pdb.set_trace()\n",
    "                            x = x_y[0]\n",
    "                            y = x_y[1]\n",
    "                            nodelist_x.append(float(x))\n",
    "                            nodelist_y.append(float(y))\n",
    "                            i+=1\n",
    "                        tsp_database.update({city[:-4]:[nodelist_x, nodelist_y]})\n",
    "    return tsp_database    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_database = gen_tsp_data()\n",
    "problem_list = tsp_database.keys()\n",
    "problem_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj as p\n",
    "#x = \"rl5934\"\n",
    "#x = \"pr1002\"\n",
    "## No Connectivty and Ward linkage\n",
    "#n_clusters = [161,21,2]\n",
    "#x = \"rl5915\"\n",
    "## No Connectivty and Ward linkage\n",
    "#n_clusters = [980, 139, 17, 2]\n",
    "#x = \"rl5934\"\n",
    "#n_clusters = [1237,196,29,4]\n",
    "#x = \"rl11849\"\n",
    "## No Connectivty and Ward linkage\n",
    "#n_clusters = [2341,375,61,7]\n",
    "#x = \"pla33810\"\n",
    "## Connectivty and Complete linkage\n",
    "#n_clusters = [6600,1417,233,39,8,1]\n",
    "## No Connectivty and Ward linkage\n",
    "#n_clusters = [6446, 1257, 192, 28, 3]\n",
    "x = \"pla85900\"\n",
    "coord_geo = False\n",
    "if coord_geo == True:\n",
    "     crs_wgs = p.Proj(init='epsg:4326')\n",
    "     crs_bng = p.Proj(init = 'epsg:27700')\n",
    "    \n",
    "     tsp_database[x][0],tsp_database[x][1]  = p.transform(crs_wgs, crs_bng, tsp_database[x][1], tsp_database[x][0])\n",
    "# for x in tsp_database:\n",
    "print(\"Problem : \" + x)\n",
    "#    print(tsp_database[x])\n",
    "X_coord = np.array(tsp_database[x][0])\n",
    "Y_coord = np.array(tsp_database[x][1])\n",
    "X_Y = np.array(list(zip(X_coord,Y_coord))).reshape(len(X_coord),2)\n",
    "plt.plot()\n",
    "plt.title('Cities in ' + x)\n",
    "plt.scatter(X_coord, Y_coord)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lt.plot()<br>\n",
    "lt.title('Cities in ' + x)<br>\n",
    "lt.scatter(X_coord, Y_coord)<br>\n",
    "lt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "\n",
    "X_Y[X_Y == inf] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustered_cities(num_clust, labels_array):\n",
    "    return np.where(labels_array == num_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sys2_cities(sys2_cities):\n",
    "    for k in K:\n",
    "        plt.scatter(sys2_cities[k][:,0], sys2_cities[k][:,1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time   \n",
    "from k_means_constrained import KMeansConstrained\n",
    "\n",
    "X_Y=[X_Y]\n",
    "KM_labels = []\n",
    "i = 0\n",
    "\n",
    "cluster_size_min = 3\n",
    "cluster_size_max = 12\n",
    "\n",
    "Contrained = False\n",
    "## 0: K-means++ // 1: Agglomerative\n",
    "Clustering_Methods = 1\n",
    "\n",
    "hierarchies = []\n",
    "\n",
    "\"\"\"if Contrained:\n",
    "    n_clusters = ceil(len(X_Y[i])/cluster_size_max)\n",
    "else:\n",
    "    n_clusters = 2\n",
    "\"\"\"\n",
    "#n_clusters = floor(len(X_Y[i])/cluster_size_max)\n",
    "n_clusters = 10000\n",
    "\n",
    "CEs = []\n",
    "clf = NearestCentroid()\n",
    "SEARCH = True\n",
    "if SEARCH:\n",
    "    while True:\n",
    "        if Contrained:\n",
    "            KMC = KMeansConstrained(\n",
    "                n_clusters = n_clusters,\n",
    "                size_min = cluster_size_min,\n",
    "                size_max = cluster_size_max,\n",
    "                random_state = 0)\n",
    "            y_KMC = KMC.fit_predict(X_Y[i])\n",
    "            centers = KMC.cluster_centers_\n",
    "        elif Clustering_Methods == 0:\n",
    "            kmeanModel = KMeans(n_clusters, init='k-means++', n_init=10).fit(X_Y[i])\n",
    "            y_KMC = kmeanModel.labels_\n",
    "            centers = kmeanModel.cluster_centers_\n",
    "        else:\n",
    "            #knn_graph = kneighbors_graph(X_Y[i], n_clusters, include_self=False)\n",
    "            #AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', connectivity= knn_graph, linkage='complete').fit(X_Y[i])\n",
    "            #AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', connectivity= knn_graph, linkage='ward').fit(X_Y[i])\n",
    "            #AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', linkage='complete').fit(X_Y[i])\n",
    "            AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', linkage='ward').fit(X_Y[i])\n",
    "            y_KMC = AggloModel.labels_\n",
    "            clf.fit(X_Y[i], y_KMC)\n",
    "            centers = clf.centroids_\n",
    "        ICC = 0\n",
    "        ICS = 0\n",
    "        n_max = 0\n",
    "        n_min = inf\n",
    "        for c in range(len(centers)):\n",
    "            center = centers[c]\n",
    "            cities = np.where(y_KMC==c)[0]\n",
    "            if len(cities) < n_min:\n",
    "                n_min = len(cities)\n",
    "            if len(cities) > n_max:\n",
    "                n_max = len(cities)\n",
    "            for city in cities:\n",
    "                ICC += sqrt((X_Y[i][city][0]-center[0])**2+(X_Y[i][city][1]-center[1])**2)\n",
    "            if len(cities) >1 :\n",
    "                ICS += ICC/len(cities)\n",
    "            ICC = 0\n",
    "            #for center2 in centers:\n",
    "            #    ICS += sqrt((center[0]-center2[0])**2+(center[1]-center2[1])**2)\n",
    "        #CE = ICC/ICS\n",
    "        CE = ICS/len(centers)\n",
    "        CEs.append(CE)\n",
    "        #Score = silhouette_score(X_Y[i], y_KMC)\n",
    "        if len(CEs) > 10:\n",
    "            MEAN = sum(CEs[-9:])/10\n",
    "        else:\n",
    "            MEAN = sum(CEs)/len(CEs)\n",
    "        print(n_clusters, n_min, n_max, CE, MEAN)\n",
    "        \n",
    "        if (n_max < cluster_size_max+1):# and (n_clusters == 2 or MEAN*0.999 < CE):# and (MinScore*1.01 > Score):\n",
    "            plt.plot(range(len(CEs)), CEs, 'r-')\n",
    "            plt.show()\n",
    "            colors = mpl.cm.tab20(range(20))\n",
    "            c_labels = []\n",
    "            for yy in y_KMC:\n",
    "                c_labels.append(colors[yy%20])\n",
    "            #plt.scatter(X_Y[i][:,0], X_Y[i][:,1], c=y_KMC, s=10, cmap='viridis')\n",
    "            plt.scatter(X_Y[i][:,0], X_Y[i][:,1], c=c_labels, s=10)\n",
    "            plt.scatter(centers[:,0], centers[:,1], c='black', s=50, alpha=0.5)\n",
    "            plt.rcParams.update({'font.size':15})\n",
    "            plt.show()\n",
    "            \n",
    "            KM_labels.append(y_KMC)\n",
    "            X_Y.append(centers)\n",
    "            hierarchies.append(len(centers))\n",
    "            i += 1\n",
    "            n_clusters = floor(len(X_Y[i])/cluster_size_max)\n",
    "            if n_clusters < 2:\n",
    "                n_clusters = 2\n",
    "            if len(centers) < cluster_size_max+1:\n",
    "                break\n",
    "            CEs = []\n",
    "        else:\n",
    "            n_clusters += 1\n",
    "else:\n",
    "    for N_C in n_clusters:\n",
    "        #knn_graph = kneighbors_graph(X_Y[i], n_clusters, include_self=False)\n",
    "        #AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', connectivity= knn_graph, linkage='complete').fit(X_Y[i])\n",
    "        #AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', connectivity= knn_graph, linkage='ward').fit(X_Y[i])\n",
    "        #AggloModel = AgglomerativeClustering(n_clusters, metric='euclidean', linkage='complete').fit(X_Y[i])\n",
    "        AggloModel = AgglomerativeClustering(N_C, metric='euclidean', linkage='ward').fit(X_Y[-1])\n",
    "        y_KMC = AggloModel.labels_\n",
    "        clf.fit(X_Y[-1], y_KMC)\n",
    "        centers = clf.centroids_\n",
    "        \n",
    "        KM_labels.append(y_KMC)\n",
    "        X_Y.append(centers)\n",
    "        hierarchies.append(len(centers))\n",
    "\n",
    "print(hierarchies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sys2_cities has [hierarchies where the sub-cluster belongs, Center X/Y coordinates of the sub-cluster, Cities X/Y coordinates in the sub-cluster]\n",
    "## sys2_centers has [hierarchies where the sub-cluster belongs, Center X/Y coordinates of the sub-cluster]\n",
    "## sys2_clusters has [hierarchies where the sub-cluster belongs, Cities X/Y coordinates in the sub-cluster]\n",
    "sys2_centers = []\n",
    "sys2_clusters = []\n",
    "\n",
    "H = range(0,len(hierarchies))\n",
    "for h in H:\n",
    "    K = range(0,hierarchies[h])\n",
    "    sys2_centers.append([])\n",
    "    sys2_clusters.append([])\n",
    "    colors = mpl.cm.tab20(range(20))\n",
    "    for k in K:\n",
    "        sys2_centers[h].append(X_Y[h+1][k])\n",
    "        sys2_clusters[h].append(X_Y[h][get_clustered_cities(k, KM_labels[h])])\n",
    "    largest_cluster_size = 0\n",
    "    smallest_cluster_size = 100\n",
    "    for k in K:\n",
    "        if len(sys2_clusters[h][k]) > largest_cluster_size:\n",
    "            largest_cluster_size = len(sys2_clusters[h][k])\n",
    "        if len(sys2_clusters[h][k]) < smallest_cluster_size:\n",
    "            smallest_cluster_size = len(sys2_clusters[h][k])\n",
    "        if (len(sys2_clusters[h][k]) == 1):\n",
    "            print(\"dirty cluster\")\n",
    "    print(\"The largest & smallest cluster size in Hierarchy \",h+1, \": \", largest_cluster_size, \" & \", smallest_cluster_size)\n",
    "## Add the topmost cluster\n",
    "sys2_centers.append([])\n",
    "sys2_clusters.append([])\n",
    "sys2_centers[-1].append([0, 0])\n",
    "sys2_clusters[-1].append(X_Y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fix_first_last_cities(sys2_centers, sys2_clusters, sol_route, Lowest_Hier):\n",
    "    ## Find a pair of the closest cities, each of which is in a distinct cluster which will be sequentially visited.\n",
    "    ## After finding, place each city of the pair in the end of the preceding cluster and the start of the following cluster.\n",
    "    ## To avoid the city in the following cluster to be selected once again for the next search, the next search starts from Index 1.\n",
    "    ## Refer to Page 25\n",
    "    tree = cKDTree(sys2_centers)\n",
    "    clust_id_list = []\n",
    "    total_traveling_distance = 0\n",
    "    \n",
    "    for k in range(len(sol_route)-1):\n",
    "        ## Finding a pair of cities from distinct sub-clusters having the shortest distance betweeen sub-clusters.\n",
    "        clust_idx_curr = tree.query(sol_route[k])[1]\n",
    "        clust_idx_next = tree.query(sol_route[k+1])[1]\n",
    "        if k ==0:\n",
    "            clust_id_list.append(clust_idx_curr)\n",
    "        clust_id_list.append(clust_idx_next)\n",
    "        \n",
    "        curr_clust = sys2_clusters[clust_idx_curr]\n",
    "        next_clust = sys2_clusters[clust_idx_next]\n",
    "        tree_clust = cKDTree(next_clust)\n",
    "        ## For the first cluster in a hierarchy, all cities in the cluster is included in the search.\n",
    "        ## For clusters that include only one city, the city that has been chosen for the first city from the previous search \n",
    "        ## will be used for the search and chosen for the last city. The first and last city at the same time. \n",
    "        if k ==0 or len(curr_clust) == 1:\n",
    "            search_init = 0\n",
    "        ## Otherwise, the first city is excluded from the search, because it's already chosen for the first city.\n",
    "        else:\n",
    "            search_init = 1\n",
    "        sht_dist = inf\n",
    "        for inc in range(search_init, len(curr_clust)):\n",
    "            val_sd, idx_sd = tree_clust.query(curr_clust[inc])\n",
    "            if val_sd < sht_dist:\n",
    "                sht_dist = val_sd\n",
    "                sht_idx_curr = inc\n",
    "                sht_idx_next = idx_sd\n",
    "                \n",
    "        ## Fix the first and the last cities according to the information found above, unless the clust has one city.\n",
    "        if len(curr_clust) > 1:\n",
    "            curr_clust[[-1, sht_idx_curr]] = curr_clust[[sht_idx_curr,-1]]\n",
    "            sys2_clusters[clust_idx_curr] = curr_clust\n",
    "        if len(next_clust) > 1:\n",
    "            next_clust[[0, sht_idx_next]] = next_clust[[sht_idx_next,0]]\n",
    "            sys2_clusters[clust_idx_next] = next_clust\n",
    "        if Lowest_Hier:\n",
    "            total_traveling_distance += sht_dist\n",
    "            #print(\"Inter-cluster distance (clusters \", k, \"-\", k+1, \"): \", sht_dist, \" total distance: \", total_traveling_distance)\n",
    "            \n",
    "    return sys2_clusters, clust_id_list, total_traveling_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_ising(Lowest_Hier, total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array, curr_clust_size, infile, outfile):\n",
    "    print(\"Ising skipped!!\")\n",
    "    timet[-1].append(0)\n",
    "    nMAC_array[-1].append(0)\n",
    "    nRandFlip_array[-1].append(0)\n",
    "    DIST = 0\n",
    "    with open(infile,\"r\") as inF:\n",
    "        lines = inF.readlines()\n",
    "        outF = open(outfile,\"w\")\n",
    "        \n",
    "        for i in range(1, curr_clust_size+1):\n",
    "            line = lines[i]\n",
    "            outF.write(line)\n",
    "            \n",
    "            curr = line.strip().split()\n",
    "            for j in range(len(curr)):\n",
    "                curr[j] = float(curr[j])\n",
    "            sol_route.append(curr)\n",
    "            \n",
    "            if Lowest_Hier:\n",
    "                if (i == 1):\n",
    "                    route_btw_clusters.append(curr)\n",
    "                if (i == curr_clust_size):\n",
    "                    route_btw_clusters.append(curr)\n",
    "        if curr_clust_size == 1:\n",
    "            DIST = 0\n",
    "        else:\n",
    "            for i in range(1, curr_clust_size):\n",
    "                X1 = float(lines[i].strip().split()[0])\n",
    "                Y1 = float(lines[i].strip().split()[1])\n",
    "                X2 = float(lines[i+1].strip().split()[0])\n",
    "                Y2 = float(lines[i+1].strip().split()[1])\n",
    "                DIST += sqrt((X1-X2)**2+(Y1-Y2)**2)\n",
    "        outF.write(\"\\n\")\n",
    "        outF.write(\"dist \")\n",
    "        outF.write(str(DIST))\n",
    "        outF.write(\"\\n\")\n",
    "        outF.write(\"n_MAC 0\")\n",
    "        outF.write(\"\\n\")\n",
    "        outF.write(\"n_RandFlip 0\")\n",
    "        outF.write(\"\\n\")\n",
    "        \n",
    "        outF.close()\n",
    "        inF.close()\n",
    "\n",
    "        if Lowest_Hier:\n",
    "            total_traveling_distance += DIST\n",
    "    \n",
    "    return total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sys2_sol(MAC_ising, benchmark, sys2_centers, sys2_clusters, SchPar):\n",
    "    MAC_ising = True\n",
    "    if MAC_ising:\n",
    "        cpp_cmd = \"./ising_mac\"\n",
    "    else :\n",
    "        cpp_cmd = \"./ising_RNG\"\n",
    "    os.system(\"rm -rf sys2clusters_\" + str(benchmark))\n",
    "    SYS2_CENTERS = sys2_centers\n",
    "    SYS2_CLUSTERS = sys2_clusters\n",
    "    \n",
    "    timet =[]\n",
    "    nMAC_array =[]\n",
    "    nRandFlip_array = []\n",
    "    sys2_labels = []\n",
    "    colors = mpl.cm.tab20(range(20))\n",
    "    sol_route = 0\n",
    "    sol_route_ex = []\n",
    "    \n",
    "    ideal_latency = 0\n",
    "    nMAC_hierarchies = []\n",
    "    \n",
    "    for h in range(0, n_hierarchies+1):\n",
    "        print(\"Execute Ising Solver for Hierarchy \", n_hierarchies-h)\n",
    "        sys2_centers = SYS2_CENTERS[n_hierarchies-h]\n",
    "        sys2_clusters = SYS2_CLUSTERS[n_hierarchies-h]\n",
    "\n",
    "        if h != 0:\n",
    "            sys2_clusters, clust_id_list, total_traveling_distance = Fix_first_last_cities(sys2_centers, sys2_clusters, sol_route, h == n_hierarchies)\n",
    "        else:\n",
    "            clust_id_list = range(0, len(sys2_centers))\n",
    "            \n",
    "        sol_route_ex.append(sol_route)\n",
    "        sol_route = []\n",
    "        route_btw_clusters = []\n",
    "        timet.append([])\n",
    "        nMAC_array.append([])\n",
    "        nRandFlip_array.append([])\n",
    "        sys2_labels.append([])\n",
    "        for k in range(len(clust_id_list)):\n",
    "            curr_clust = sys2_clusters[clust_id_list[k]]\n",
    "            curr_clust_size = len(curr_clust)\n",
    "            for l in range(curr_clust_size):\n",
    "                sys2_labels[h].append(colors[k%20])\n",
    "            os.system(\"mkdir -p sys2clusters_\" + str(benchmark))\n",
    "            curr_filename = str(benchmark) + \"_h\" + str(n_hierarchies-h)  + \"_c\" + str(k) +\".in\"\n",
    "            curr_logfile = str(benchmark) + \"_h\" + str(n_hierarchies-h)   + \"_c\" + str(k) +\".out\"\n",
    "            inF = open(\"sys2clusters_\" + str(benchmark) + \"/\" + curr_filename,\"w\")\n",
    "            inF.write(str(curr_clust_size))\n",
    "            inF.write(\"\\n\")\n",
    "            for i in curr_clust:\n",
    "                inF.write(str(i[0]) + \" \" + str(i[1]))\n",
    "                inF.write(\"\\n\")\n",
    "            inF.close()\n",
    "            \n",
    "            if h == 0:\n",
    "                if curr_clust_size == 2:\n",
    "                    total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array = skip_ising(h == n_hierarchies, 0, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array, curr_clust_size, \"sys2clusters_\" + str(benchmark) + \"/\" + curr_filename, \"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile)\n",
    "                    continue\n",
    "            else:\n",
    "                if k == 0 or k == len(clust_id_list)-1:\n",
    "                    if curr_clust_size < 3:\n",
    "                        total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array = skip_ising(h == n_hierarchies, total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array, curr_clust_size, \"sys2clusters_\" + str(benchmark) + \"/\" + curr_filename, \"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile)\n",
    "                        continue\n",
    "                else:\n",
    "                    if curr_clust_size < 4:\n",
    "                        total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array = skip_ising(h == n_hierarchies, total_traveling_distance, sol_route, route_btw_clusters, timet, nMAC_array, nRandFlip_array, curr_clust_size, \"sys2clusters_\" + str(benchmark) + \"/\" + curr_filename, \"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile)\n",
    "                        continue\n",
    "            tic = time.perf_counter()\n",
    "            ### when h>0, Problem_size to optimize = N-1 when k is 0 or -1, otherwise N-2\n",
    "            if h == 0 :\n",
    "                os.system(cpp_cmd+\" -I \"+str(SchPar[0])+\" -c \"+str(SchPar[1])+\" -F \"+str(SchPar[2])+\" -D \"+str(SchPar[3])+\" -P \"+str(SchPar[4])+\" k0\" + \" sys2clusters_\" + str(benchmark) + \"/\" + curr_filename + \" >> \" + \"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile)\n",
    "            elif k == len(clust_id_list)-1:\n",
    "                os.system(cpp_cmd+\" -I \"+str(SchPar[0])+\" -c \"+str(SchPar[1])+\" -F \"+str(SchPar[2])+\" -D \"+str(SchPar[3])+\" -P \"+str(SchPar[4])+\" k-1\" + \" sys2clusters_\" + str(benchmark) + \"/\" + curr_filename + \" >> \" + \"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile)\n",
    "            else :\n",
    "                os.system(cpp_cmd+\" -I \"+str(SchPar[0])+\" -c \"+str(SchPar[1])+\" -F \"+str(SchPar[2])+\" -D \"+str(SchPar[3])+\" -P \"+str(SchPar[4])+\" k\" + str(k+1) + \" sys2clusters_\" + str(benchmark) + \"/\" + curr_filename + \" >> \" + \"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile)\n",
    "            toc = time.perf_counter()\n",
    "            timet[-1].append(toc-tic)\n",
    "            \n",
    "            dist_array =[]\n",
    "            with open(\"sys2clusters_\" + str(benchmark) + \"/\" + curr_logfile,\"r\") as outFile:\n",
    "                lines = outFile.readlines()\n",
    "                for i in range(0,len(lines)):\n",
    "                    line = lines[i]\n",
    "                    if \"dist\" in line:\n",
    "                        dist_array.append(line.strip().split()[1])\n",
    "                        continue\n",
    "                    if \"n_MAC\" in line:\n",
    "                        nMAC_array[-1].append(int(line.strip().split()[1]))\n",
    "                        continue\n",
    "                    if \"n_RandFlip\" in line:\n",
    "                        nRandFlip_array[-1].append(int(line.strip().split()[1]))\n",
    "                        continue\n",
    "                dist = min(dist_array)\n",
    "                ####################################\n",
    "                ####################################\n",
    "                if h == n_hierarchies:\n",
    "                    total_traveling_distance += float(dist)\n",
    "                    print(\"hierarchy: \", h, \" cluster: \", k, \" distance within the cluster: \", float(dist), \" total distance: \", total_traveling_distance)\n",
    "                ####################################\n",
    "                ####################################\n",
    "                for i in range(0, curr_clust_size):\n",
    "                    line = lines[i]\n",
    "                    curr = line.strip().split()\n",
    "                    for j in range(len(curr)):\n",
    "                        curr[j] = float(curr[j])\n",
    "                    sol_route.append(curr)\n",
    "                \n",
    "                    if h == n_hierarchies:\n",
    "                        if (i == 0) or (i == curr_clust_size-1):\n",
    "                            route_btw_clusters.append(curr)\n",
    "                \n",
    "                outFile.close()\n",
    "            print(\"done with cluster\" + str(k))\n",
    "        #print(f\"Ising Max time = {max(timet[-1]):0.4f} seconds\", \" / \", str(min(timet[-1])))\n",
    "        ideal_latency += max(timet[-1])\n",
    "        nMAC_hierarchies.append(max(nMAC_array[-1]))\n",
    "        if MAC_ising:\n",
    "            print(f\"Max/Min number of Ising Macro MAC Operations = \", max(nMAC_array[-1]), \" / \", min(nMAC_array[-1]))\n",
    "            #print(f\"Max/Min number of Ising Macro RandomFlip Operations = \", max(nRandFlip_array[-1]), \" / \", min(nRandFlip_array[-1]))\n",
    "    \n",
    "    print(\"total wall-clock latency: \", ideal_latency)\n",
    "    print(\"Max nMAC per hierarchy: \", nMAC_hierarchies)\n",
    "    print(\"total traveling distance: \", total_traveling_distance)\n",
    "    return sol_route_ex, sol_route, route_btw_clusters, sys2_labels, total_traveling_distance, nMAC_array, nRandFlip_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hierarchies)\n",
    "n_hierarchies = len(hierarchies)\n",
    "MAC_ising = True\n",
    "#sol_route, route_btw_clusters, sys2_labels = gen_sys2_sol(MAC_ising, x, sys2_centers, sys2_clusters)\n",
    "init_Irands = [48]\n",
    "init_cools = [0.001]\n",
    "Factors = [0.9]\n",
    "Thresholds = [0]\n",
    "Patiences = [10000]\n",
    "\n",
    "#cools = [0.01, 0.005, 0.002, 0.001]\n",
    "#Factors = [0.8, 0.9, 0.95, 0.99, 0.995, 0.999]\n",
    "#Thresholds = [1e6, 1e3, 0, -1e3, -1e6]\n",
    "#Patiences = [5, 10, 20, 50]\n",
    "ttds = []\n",
    "nMACs = []\n",
    "nRandFlips = []\n",
    "\n",
    "repeat = 1\n",
    "\n",
    "for REPEAT in range(repeat):\n",
    "    for Irand in init_Irands:\n",
    "        for cool in init_cools:\n",
    "            for Factor in Factors:\n",
    "                for Threshold in Thresholds:\n",
    "                    for Patience in Patiences:\n",
    "                        scheduler_params = [Irand, cool, Factor, Threshold, Patience]\n",
    "                        sol_route_ex, sol_route, route_btw_clusters, sys2_labels, ttd, nMAC, nRandFlip = gen_sys2_sol(MAC_ising, x, sys2_centers, sys2_clusters, scheduler_params)\n",
    "                        ttds.append(ttd)\n",
    "                        sum_nMACs = 0\n",
    "                        for MAC in nMAC:\n",
    "                            sum_nMACs += max(MAC)\n",
    "                        #nMACs.append(max(nMAC[-1]))\n",
    "                        nMACs.append(sum_nMACs)\n",
    "                        sum_nRFlips = 0\n",
    "                        for RFlip in nRandFlip:\n",
    "                            sum_nRFlips += max(RFlip)\n",
    "                        #nRandFlips.append(max(nRandFlip[-1]))\n",
    "                        nRandFlips.append(sum_nRFlips)\n",
    "    i = 0\n",
    "    for Irand in init_Irands:\n",
    "        for cool in init_cools:\n",
    "            for Factor in Factors:\n",
    "                for Threshold in Thresholds:\n",
    "                    for Patience in Patiences:\n",
    "                        print(\"Irand: \", Irand, \"Cool: \", cool, \"Factor: \", Factor, \" Threshold: \", Threshold, \" Patience: \", Patience, \" ttd: \", ttds[i], \" nMAC: \", nMACs[i], \" nRandFlip: \", nRandFlips[i])\n",
    "                        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    route = np.array(route_btw_clusters)\n",
    "    sol_route = np.array(sol_route)\n",
    "    for n in range(int(len(route_btw_clusters)/2)-1):\n",
    "        plt.plot(route[2*n+1:2*(n+1)+1,0], route[2*n+1:2*(n+1)+1,1], '-')\n",
    "    plt.scatter(sol_route[:,0], sol_route[:,1], c=sys2_labels[n_hierarchies][:], s=20)\n",
    "\n",
    "    colors = 'rbk'\n",
    "    sol_route_ex = sol_route_ex[1:]\n",
    "    for H in range(len(sol_route_ex)):\n",
    "        for n in range(len(sol_route_ex[H])):\n",
    "            plt.text(sol_route_ex[H][n][0],sol_route_ex[H][n][1], str(n+1), fontsize = 10*(len(sol_route_ex)-H), color = colors[H])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def compute_geo(p1,p2):\n",
    "    R = 6373.0\n",
    "    \n",
    "    lat1 = radians(float(p1[0]))\n",
    "    lon1 = radians(float(p1[1]))\n",
    "    lat2 = radians(float(p2[0]))\n",
    "    lon2 = radians(float(p2[1]))\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 -lat1\n",
    "\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "    c = 2*atan2(sqrt(a),sqrt(1-a))\n",
    "    dist = R*c\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_geo == False\n",
    "if coord_geo == True:\n",
    "#     test = np.load(\"sys2clusters_\" + str(x) + \"/sol_table.npy\", allow_pickle=True)\n",
    "    for i in range(len(test)):\n",
    "        print(i)\n",
    "        for j in range(len(test[i])):\n",
    "            geo_dist = 0\n",
    "            li = test[i][j][1]\n",
    "            for idx,elem in enumerate(li):\n",
    "                thiscity = elem\n",
    "                nextcity = li[(idx+1)%len(li)]\n",
    "                geo_dist += compute_geo(thiscity, nextcity)\n",
    "            test[i][j][2] = geo_dist \n",
    "            print(geo_dist)\n",
    "        np.save(\"sys2clusters_\" + str(x) + \"/sol_table\" ,test)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mport pdb; pdb.set_trace()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sangmin edited\n",
    "GO = False\n",
    "if GO:\n",
    "    with open(\"tsp\" + x + \"_pyconcorde.txt\", \"w\") as f:\n",
    "        solver = TSPSolver.from_data(X_coord, Y_coord, norm=\"EUC_2D\")  \n",
    "        solution = solver.solve()\n",
    "        f.write( str(\" \") + str('output') + str(\" \") )\n",
    "        f.write( str(\"solution found? \") + str(solution.found_tour) + str(\" \") )\n",
    "        f.write( str(\"Optimal value? \") + str(solution.optimal_value) + str(\" \") )\n",
    "        f.write( str(\" \").join( str(node_idx+1) for node_idx in solution.tour) )\n",
    "        f.write( str(\" \") + str(solution.tour[0]+1) + str(\" \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = False\n",
    "if GO:\n",
    "    num_samples = 10000\n",
    "    set_nodes_coord = np.random.random([num_samples, n_clusters, 2])\n",
    "    with open(\"tsp\" + str(n_clusters) + \"_pr1002.txt\", \"w\") as f:\n",
    "        solver = TSPSolver.from_data(centers[:,0], centers[:,1], norm=\"EUC_2D\")  \n",
    "        solution = solver.solve()\n",
    "        f.write( \" \".join( str(x)+str(\" \")+str(y) for x,y in centers) )\n",
    "        f.write( str(\" \") + str('output') + str(\" \") )\n",
    "        f.write( str(\" \").join( str(node_idx+1) for node_idx in solution.tour) )\n",
    "        f.write( str(\" \") + str(solution.tour[0]+1) + str(\" \") )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ising",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
